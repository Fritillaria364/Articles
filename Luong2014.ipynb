{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addressing the Rare Word Problem in Neural Machine Translation\n",
    "Minh-Thang Luong et al."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. あぶすと\n",
    "NMTは従来の手法より良い結果出してるすげーやつ  \n",
    "でも従来の小規模の語彙でOOVの可能性がある単語をUNKタグで表現するようなend2endのNMTモデルだと、低頻度語句をちゃんと翻訳できない  \n",
    "本論文ではこの問題に効率的に対処する手法を提案する  \n",
    "\n",
    "ターゲット文に出現する各OOV単語について、NMTシステムがソース文の関連する単語の位置を出力することを可能とする単語アライメントアルゴリズムの出力によって補完されたデータを用いてNMTシステムを訓練する  \n",
    "この(位置)情報は、各OOV単語を辞書を用いて翻訳する後処理のステップで利用される"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. いんとろ\n",
    "NMTはナウでヤングでいけてるすごいの  \n",
    "一方で従来のNMTは、低頻度語を翻訳できないみたいなところある  \n",
    "なぜなら固定サイズの小規模語彙しか持ってないから、多くのOOV単語を表現するのに*unk*シンボル一つを使うしかない  \n",
    "低頻度を多く含む文章は、頻出語を主として含む文章よりも貧弱な翻訳をされる傾向にある  \n",
    "一方で通常のフレーズベースドなシステムでは、より多くの語彙を用いることができる上、明示的なアライメントやフレーズテーブルによって低頻度語の翻訳をメモ化できるため、同様の問題は起こらない  \n",
    "このようなフレーズベースドなシステムの強みをモチベーションに、NMTにおける低頻度語の問題に対処する新しい手法を提案する  \n",
    "\n",
    "提案手法では、各OOV単語についてそれと関係するソース文の単語を指す\"ポインター\"をNMTが出力できるような、明示的なアライメント情報を訓練コーパスにアノテートする  \n",
    "この情報は後処理のステップで翻訳が見つからないOOV単語を辞書を使って翻訳する際に使われる  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. NMT\n",
    "いつもの  \n",
    "LSTM使ったenc-decモデル使う  \n",
    "\n",
    "NMTの先行研究で低頻度語問題に対処したものはない(2015年時点)けど、Jeanら(2015)がでかい語彙を扱うためにsoftmaxを効率的に近似する手法を最近提案した  \n",
    "でも大きな語彙があっても、人名とか数字とかでは依然として問題が残る  \n",
    "それに対処するためにはワイらの提案するみたいな手法を使ったほうがよいってjeanらは言ってて、彼らのアプローチと相補的であるといえる  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Rare Word Models\n",
    "非常に多くのNMTの研究があるにも関わらず、Jeanらのそれを除けば低頻度語を対処する研究はまったくなかった  \n",
    "\n",
    "で、こういう低頻度語に対処するために、ターゲット文における未知語の元を辿れるようなNMTの学習を提案する  \n",
    "もしターゲット文の各未知語に対応するソース文の単語がわかってたら、システムが出力した*unk*を後処理で辞書なりなんなり使って翻訳すればいい  \n",
    "このようなアノテーションの方法について、我々はどんなNMTシステムにも容易に適用できる三つの手法を示す  \n",
    "NMTシステムをブラックボックスとして扱い、次に示す方法を用いてアノテートされたコーパスを用いて訓練する  \n",
    "\n",
    "1. 教師なしalighnerを用いてアライメントを生成\n",
    "1. アライメントの対応を使って、後処理ステップの単語翻訳で使用する単語辞書を構築\n",
    "1. もし単語が辞書内にない場合はidentity translationを使用\n",
    "\n",
    "### 3.1 Copyable Model\n",
    "このアプローチでは, ソース文とターゲット文にある様々な未知語を表現するために, ただ1つのunkトークンでなく複数のトークンを導入する  \n",
    "ソース文にあるOOV単語へ, 出現順にunk1,unk2.unk3と割り当て, 同じ未知語には同じトークンを割り当てる  \n",
    "ターゲット文における未知語へのアノテーションはもうすこし複雑  \n",
    "1. ソース文の未知語と対応が取られているターゲット文の各未知語は, ソース文と同じトークンで置き換えられる(ゆえに\"Copyable\"モデル)\n",
    "1. アライメントがない, または既知単語と対応があるターゲット文の未知語には特殊なトークンunk∅が割り当てられる\n",
    "\n",
    "### 3.2 Positional All Model(PosAll)\n",
    "copyableモデルは,既知単語とアライメントが取られている単語は翻訳できないという制限があった(同一のトークンで置換されるため)  \n",
    "これは, ソース語彙がターゲット語彙より大きくなりがちなためよく発生する  \n",
    "この制限から, ソース文とターゲット文間の完全なアライメントを含むアノテーションを開発することを考えた  \n",
    "(seq2seqでは)完全なアライメントが訓練時に利用可能であるため, 取得するのは容易(アテンションのこと言ってる？)  \n",
    "このモデルではソース文では単一のunkトークンを用いる  \n",
    "一方でターゲット文ではすべての単語の後ろにポジショントークン$p_d(d=-7,-6,-5,...-1,0,1,...,7)$を挿入する  \n",
    "このポジショントークンは, その直前の単語の位置がjであるとき, ソース文の$i = j - d$番目と対応することを表す  \n",
    "距離が離れすぎているアライメント(|d|>7?)はアライメントが取れていないとみなされ, それに限らずアライメントが取れない単語にはNULLトークン$p_n$が付けられる\n",
    "\n",
    "### 3.3 Positional Unknown Model(PosUnk)\n",
    "PosAllモデルの弱点はターゲット文の系列長が倍になってしまい, 学習が難しくなるしパラメータの更新が遅くなる  \n",
    "でも, ワイらの後処理ステップが未知語のアライメントにのみ関係していることを踏まえると, 未知語にのみアノテートするほうがいいことは明白  \n",
    "よって, $unkpos_d$というトークンを使って単語が未知であり, その未知語に対応するソース単語の相対的な位置dを表すPosUnkモデルを考えた  \n",
    "PosAllモデルのように, アライメントがない未知語は$unkpos_∅$でおく  \n",
    "またソース文のすべての未知語には同一のunkトークンを用いる  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experiment\n",
    "WMT14の英仏タスクで学習したOOVモデルの性能を評価  \n",
    "翻訳の性能はnewstest2014の3003文をBLEUで計測  \n",
    "\n",
    "### 4.1 Training Data\n",
    "データにはWMT14の12M文を用いる  \n",
    "ソフトマックス層の計算量を考慮して、仏(ターゲット)語彙を40k or 80kに、英(ソース)語彙を200kに頻度の高い順で設定した  \n",
    "この語彙から漏れた単語は全部未知語として扱い、提案モデルで対処する対象とした  \n",
    "アライメントの作成にはBerkeley alignerをデフォルト設定で使い、ソース/ターゲットどちらかが100単語を超える対訳は除いた  \n",
    "\n",
    "### 4.2 Training Details\n",
    "めんどくさい\n",
    "\n",
    "### 4.3 A note on BLEU scores\n",
    "デトークナイズしてうんしてホイする\n",
    "\n",
    "### 4.4 Main Result\n",
    "8LSTMのアンサンブル＋PosUnkモデルがSOTA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
